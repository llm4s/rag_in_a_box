# RAG in a Box - Application Configuration

server {
  host = "0.0.0.0"
  host = ${?SERVER_HOST}
  port = 8080
  port = ${?SERVER_PORT}
}

database {
  # PostgreSQL connection settings
  host = "localhost"
  host = ${?PG_HOST}
  port = 15432
  port = ${?PG_PORT}
  database = "ragdb"
  database = ${?PG_DATABASE}
  user = "rag"
  user = ${?PG_USER}
  password = "rag"
  password = ${?PG_PASSWORD}

  # Table name for vector embeddings
  table-name = "rag_embeddings"
  table-name = ${?PG_TABLE_NAME}

  # Alternative: Use DATABASE_URL if provided
  # Format: postgresql://user:password@host:port/database
  url = ${?DATABASE_URL}
}

embedding {
  # Provider: openai, voyage, ollama
  provider = "openai"
  provider = ${?EMBEDDING_PROVIDER}

  # Model name (provider-specific)
  model = "text-embedding-3-small"
  model = ${?EMBEDDING_MODEL}

  # Embedding dimensions (auto-detected if not specified)
  # dimensions = 1536
}

llm {
  # LLM model for answer generation
  # Format: provider/model (e.g., openai/gpt-4o, anthropic/claude-3-opus)
  model = "openai/gpt-4o"
  model = ${?LLM_MODEL}

  # Temperature for answer generation
  temperature = 0.1
  temperature = ${?LLM_TEMPERATURE}
}

rag {
  # Chunking settings
  chunking {
    # Strategy: simple, sentence, markdown, semantic
    strategy = "sentence"
    strategy = ${?RAG_CHUNKING_STRATEGY}

    # Target chunk size in characters
    size = 800
    size = ${?RAG_CHUNK_SIZE}

    # Overlap between chunks in characters
    overlap = 150
    overlap = ${?RAG_CHUNK_OVERLAP}
  }

  # Search settings
  search {
    # Default number of context chunks to retrieve
    top-k = 5
    top-k = ${?RAG_TOP_K}

    # Fusion strategy: rrf, weighted, vector_only, keyword_only
    fusion-strategy = "rrf"
    fusion-strategy = ${?RAG_FUSION_STRATEGY}

    # RRF k parameter (only used with rrf strategy)
    rrf-k = 60
    rrf-k = ${?RAG_RRF_K}
  }

  # System prompt for answer generation
  system-prompt = """You are a helpful assistant that answers questions based on the provided context.
Use only the information from the context to answer the question.
If the context doesn't contain enough information, say so.
Be concise and accurate."""
  system-prompt = ${?RAG_SYSTEM_PROMPT}
}

# API keys (required - no defaults for security)
api-keys {
  openai = ${?OPENAI_API_KEY}
  openai = ${?OPEN_AI_KEY}
  anthropic = ${?ANTHROPIC_API_KEY}
  voyage = ${?VOYAGE_API_KEY}
}

# Security settings
security {
  # API key for authenticating requests (legacy mode, optional)
  # When set, all requests must include X-API-Key header or ?api_key query param
  api-key = ${?API_KEY}

  # Allow X-Admin header to bypass permission checks
  # SECURITY WARNING: This is disabled by default. Only enable in development
  # or when API key authentication is also enabled to protect the endpoint.
  allow-admin-header = false
  allow-admin-header = ${?ALLOW_ADMIN_HEADER}

  # Authentication configuration
  auth {
    # Authentication mode: open, basic, oauth
    # - open: No authentication required (default)
    # - basic: Username/password with JWT tokens
    # - oauth: OAuth2/OIDC (future)
    mode = "open"
    mode = ${?AUTH_MODE}

    # Basic auth settings (only used when mode = "basic")
    basic {
      # Default admin username
      admin-username = "admin"
      admin-username = ${?ADMIN_USERNAME}

      # Admin password (required when mode = "basic")
      admin-password = ${?ADMIN_PASSWORD}
    }

    # JWT settings
    jwt-secret = ${?JWT_SECRET}
    jwt-expiration = 86400  # 24 hours in seconds
    jwt-expiration = ${?JWT_EXPIRATION}
  }
}

# Metrics and observability
metrics {
  # Enable Prometheus metrics endpoint at /metrics
  enabled = false
  enabled = ${?METRICS_ENABLED}
}

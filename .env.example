# RAG in a Box - Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# API Keys (at least one LLM provider required)
# =============================================================================

# OpenAI API key (required for OpenAI embeddings and LLM)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API key (optional, for Claude models)
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# VoyageAI API key (optional, for Voyage embeddings)
# VOYAGE_API_KEY=pa-your-voyage-key-here

# =============================================================================
# Server Settings
# =============================================================================

# Server bind address and port
SERVER_HOST=0.0.0.0
SERVER_PORT=8080

# =============================================================================
# Database Settings
# =============================================================================

# PostgreSQL connection (individual settings)
PG_HOST=localhost
PG_PORT=15432
PG_DATABASE=ragdb
PG_USER=rag
PG_PASSWORD=rag

# Alternative: Full connection URL (overrides individual settings)
# DATABASE_URL=postgresql://rag:rag@localhost:15432/ragdb

# =============================================================================
# Embedding Settings
# =============================================================================

# Embedding provider: openai, voyage, ollama
EMBEDDING_PROVIDER=openai

# Embedding model (provider-specific)
# OpenAI: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
# Voyage: voyage-3, voyage-3-lite, voyage-code-3
# Ollama: nomic-embed-text, mxbai-embed-large
EMBEDDING_MODEL=text-embedding-3-small

# =============================================================================
# LLM Settings
# =============================================================================

# LLM model for answer generation (format: provider/model)
# OpenAI: openai/gpt-4o, openai/gpt-4o-mini, openai/gpt-4-turbo
# Anthropic: anthropic/claude-3-opus, anthropic/claude-3-sonnet, anthropic/claude-3-haiku
LLM_MODEL=openai/gpt-4o

# Temperature for LLM responses (0.0 - 1.0)
LLM_TEMPERATURE=0.1

# =============================================================================
# RAG Settings
# =============================================================================

# Chunking strategy: simple, sentence, markdown, semantic
RAG_CHUNKING_STRATEGY=sentence

# Target chunk size in characters
RAG_CHUNK_SIZE=800

# Overlap between chunks in characters
RAG_CHUNK_OVERLAP=150

# Number of context chunks to retrieve
RAG_TOP_K=5

# Search fusion strategy: rrf, weighted, vector_only, keyword_only
RAG_FUSION_STRATEGY=rrf

# =============================================================================
# Ingestion Settings (Built-in Connectors)
# =============================================================================

# Directory to ingest on startup
# INGEST_DIR=/data/docs

# File patterns to include (comma-separated)
# INGEST_PATTERNS=*.md,*.txt,*.pdf

# Recursive directory scanning
# INGEST_RECURSIVE=true

# Run ingestion on startup
# INGEST_ON_STARTUP=true

# Ingestion schedule (e.g., "6h", "daily", "0 */6 * * *")
# INGEST_SCHEDULE=6h

# =============================================================================
# API Authentication (Optional)
# =============================================================================

# API key for authenticating requests (leave empty to disable)
# API_KEY=your-secret-api-key

# =============================================================================
# Observability (Optional)
# =============================================================================

# Log level: DEBUG, INFO, WARN, ERROR
LOG_LEVEL=INFO

# Enable Prometheus metrics endpoint at /metrics
# METRICS_ENABLED=true
